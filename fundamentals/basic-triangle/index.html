<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Document</title>
</head>

<body style="background-color: black;">
  <canvas></canvas>
  <!-- <canvas width="15" height="11"></canvas> -->
</body>
<script type="module">
  // https://webgpufundamentals.org/webgpu/lessons/webgpu-fundamentals.html

  // WebGPU is an asynchronous API so itâ€™s easiest to use in an async function.
  const main = async () => {
    const adapter = await navigator.gpu?.requestAdapter()
    const device = await adapter?.requestDevice()
    if (!device) {
      fail('browser does not support WebGPU')
    }

    const canvas = document.querySelector('canvas')
    const context = canvas.getContext('webgpu')
    const presentationFormat = navigator.gpu?.getPreferredCanvasFormat() //either rgba8unorm or bgra8unorm
    context.configure({
      device,
      format: presentationFormat,
    })

    // inline wgsl

    // const shaderCode = /* wgsl */`
    //   @vertex fn vs(
    //     @builtin(vertex_index) vertexIndex : u32
    //   ) -> @builtin(position) vec4f {
    //     let pos = array(
    //       vec2f( 0.0,  0.5),  // top center
    //       vec2f(-0.5, -0.5),  // bottom left
    //       vec2f( 0.5, -0.5)   // bottom right
    //     );

    //     return vec4f(pos[vertexIndex], 0.0, 1.0);
    //   }

    //   @fragment fn fs() -> @location(0) vec4f {
    //     return vec4f(1.0, 0.0, 0.0, 1.0);
    //   }
    // `

    // load WGSL code from external file
    const response = await fetch('shaders.wgsl')
    const shaderCode = await response.text()

    const module = device.createShaderModule({
      label: 'our hardcoded red triangle shaders',
      code: shaderCode,
    });

    const pipeline = device.createRenderPipeline({
      label: 'our hardcoded red triangle pipeline',
      layout: 'auto',
      vertex: {
        // entryPoint: 'vs', // can comment out if only one function of type
        module,
      },
      fragment: {
        // entryPoint: 'fs',
        module,
        targets: [{ format: presentationFormat }],
      },
    })

    const renderPassDescriptor = {
      label: 'our basic canvas renderPass',
      colorAttachments: [
        {
          // view: <- to be filled out when we render
          clearValue: [0.3, 0.3, 0.3, 1],
          loadOp: 'clear',
          storeOp: 'store',
        },
      ],
    }

    const render = () => {
      // GEt the current texture from the canvas context and
      // set it as the texture to render to
      renderPassDescriptor.colorAttachments[0].view =
        context.getCurrentTexture().createView()

      // make a command encoder to start encoding commands
      const encoder = device.createCommandEncoder({ label: 'our encoder' })

      // make a render pass encoder to encode render specific commands
      const pass = encoder.beginRenderPass(renderPassDescriptor)
      pass.setPipeline(pipeline)
      pass.draw(3) //call our vertex shader 3 times
      pass.end()

      const commandBuffer = encoder.finish()
      device.queue.submit([commandBuffer])
    }

    // render()
    const observer = new ResizeObserver(entries => {
      for (const entry of entries) {
        const canvas = entry.target
        const width = entry.contentBoxSize[0].inlineSize
        const height = entry.contentBoxSize[0].blockSize
        canvas.width = Math.max(1, Math.min(width, device.limits.maxTextureDimension2D))
        canvas.height = Math.max(1, Math.min(height, device.limits.maxTextureDimension2D))
        //re-render
        render()
      }
    })
    observer.observe(canvas)
  }

  const fail = () => {
    alert(msg)
  }

  main()
</script>
<style>
  html,
  body {
    margin: 0;
    height: 100%;
  }

  canvas {
    display: block;
    width: 100%;
    height: 100%;
  }
</style>

</html>